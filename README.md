# Video Generation Project with Automatic Subtitles

This project automates the creation of videos with audio generated by ChatTTS and synchronized subtitles, using Whisper and MoviePy.

## Table of Contents

- [1. Prerequisites](#1-prerequisites)  
- [2. Clone the Repository](#2-clone-the-repository)  
- [3. Virtual Environment Setup](#3-virtual-environment-setup)  
- [4. Dependency Installation](#4-dependency-installation)  
- [5. Input Files and Models Preparation](#5-input-files-and-models-preparation)  
- [6. Run the Script](#6-run-the-script)  
- [7. Project Folder Structure](#7-project-folder-structure)

---

## 1. Prerequisites

Make sure you have the following installed on your system:

- **Python 3.8 or higher**: [python.org](https://www.python.org)
- **Git**: [git-scm.com](https://git-scm.com)
- **FFmpeg**: Required by MoviePy to process video and audio.

**Installation:**

- **Windows**: Download from [ffmpeg.org](https://ffmpeg.org) and add to PATH  
- **macOS**: `brew install ffmpeg`  
- **Linux**:  
  ```bash
  sudo apt update && sudo apt install ffmpeg
  ```

**GPU (Optional but Recommended)**:  
If you have an NVIDIA GPU compatible with CUDA, audio generation and transcription will be much faster. Make sure you have NVIDIA drivers and CUDA Toolkit installed.

---

## 2. Clone the Repository

Open your terminal or command prompt and execute:

```bash
git clone <YOUR_REPOSITORY_URL>
cd your-project-name  # Replace with the name of the cloned folder
```

---

## 3. Virtual Environment Setup

It's good practice to create a virtual environment to isolate project dependencies:

```bash
python -m venv .venv
```

**Activate the virtual environment:**

- **Windows:**
  ```bash
  .venv\Scripts\activate
  ```

- **macOS/Linux:**
  ```bash
  source .venv/bin/activate
  ```

You should see `(.venv)` in your terminal prompt, indicating the environment is active.

---

## 4. Dependency Installation

With the virtual environment activated, install all project dependencies:

```bash
pip install -r requirements.txt
```

---

## 5. Input Files and Models Preparation

The project expects certain files in specific folders:

### Voice Models (speaker_men.pt, speaker_women.pt)

Place these pre-trained voice models in the `voices/` folder:

```
voices/speaker_men.pt  
voices/speaker_women.pt
```

If you don’t have them, refer to ChatTTS documentation to generate or download them.

---

### ChatTTS Models (asset folder)

The `asset/` folder contains internal models downloaded automatically on first use.  
No need to manage this manually.

---

### Input Text File (input_text.txt)

This file contains the text for ChatTTS to convert into speech.

Create or edit:

```
texts/input_text.txt
```

---

### Background Video (Minecraft.mp4)

This is the video that will be used as background.

Place it at:

```
videos/Minecraft.mp4
```

You can change the filename or update the `input_video_filename` variable in `main.py`.

---

## 6. Run the Script

Once everything is set up, run:

```bash
python main.py
```

The script will:

1. Generate audio from `input_text.txt` using ChatTTS  
2. Transcribe the audio and create subtitles (`.srt`)  
3. Combine background video, audio, and subtitles (split into 3-word segments)  
4. Output the final video to:

```
final_video/output_video_with_subtitles.mp4
```

---

## 7. Project Folder Structure

```
.
├── .venv/                      # Virtual environment (ignored by Git)
├── asset/                      # ChatTTS models (auto-downloaded, ignored by Git)
├── audio/                      # Generated audio
│   └── .gitkeep
├── final_video/                # Final video output
│   └── .gitkeep
├── subtitles/                  # Generated subtitles
│   └── .gitkeep
├── texts/                      # Input text
│   └── .gitkeep
├── videos/                     # Background video
│   └── .gitkeep
├── voices/                     # Voice models
├── .gitignore                  # Git ignore file
├── main.py                     # Main script
└── requirements.txt            # Dependency list
```
